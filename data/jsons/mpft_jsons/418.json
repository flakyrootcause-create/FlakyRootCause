{
  "id": 418,
  "repo": "agent-memory-server",
  "issue_url": "https://github.com/redis/agent-memory-server/commit/2d2f4a16f266e59a9379dad76845520c65920faf",
  "pr_url": "https://github.com/redis/agent-memory-server/commit/2d2f4a16f266e59a9379dad76845520c65920faf",
  "issue_description": "Experiment with a new background task library that uses Redis Streams",
  "files_changed": [
    {
      "filename": "README.md",
      "status": "modified",
      "patch": "@@ -279,3 +279,35 @@ python -m pytest\n 3. Commit your changes\n 4. Push to the branch\n 5. Create a Pull Request\n+\n+## Running the Background Task Worker\n+\n+The Redis Memory Server uses Docket for background task management. There are two ways to run the worker:\n+\n+### 1. Using the Docket CLI\n+\n+After installing the package, you can run the worker using the Docket CLI command:\n+\n+```bash\n+docket worker --tasks agent_memory_server.docket_tasks:task_collection\n+```\n+\n+You can customize the concurrency and redelivery timeout:\n+\n+```bash\n+docket worker --tasks agent_memory_server.docket_tasks:task_collection --concurrency 5 --redelivery-timeout 60\n+```\n+\n+### 2. Using Python Code\n+\n+Alternatively, you can run the worker directly in Python:\n+\n+```bash\n+python -m agent_memory_server.worker\n+```\n+\n+With customization options:\n+\n+```bash\n+python -m agent_memory_server.worker --concurrency 5 --redelivery-timeout 60\n+```"
    },
    {
      "filename": "agent_memory_server/api.py",
      "status": "modified",
      "patch": "@@ -1,9 +1,10 @@\n from typing import Literal\n \n-from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException\n+from fastapi import APIRouter, Depends, HTTPException\n \n from agent_memory_server import long_term_memory, messages\n from agent_memory_server.config import settings\n+from agent_memory_server.dependencies import get_background_tasks\n from agent_memory_server.llms import get_model_config\n from agent_memory_server.logging import get_logger\n from agent_memory_server.models import (\n@@ -130,14 +131,15 @@ async def get_session_memory(\n async def put_session_memory(\n     session_id: str,\n     memory: SessionMemory,\n-    background_tasks: BackgroundTasks,\n+    background_tasks=Depends(get_background_tasks),\n ):\n     \"\"\"\n     Set session memory. Replaces existing session memory.\n \n     Args:\n         session_id: The session ID\n         memory: Messages and context to save\n+        background_tasks: DocketBackgroundTasks instance (injected automatically)\n \n     Returns:\n         Acknowledgement response\n@@ -179,26 +181,25 @@ async def delete_session_memory(\n \n @router.post(\"/long-term-memory\", response_model=AckResponse)\n async def create_long_term_memory(\n-    payload: CreateLongTermMemoryPayload, background_tasks: BackgroundTasks\n+    payload: CreateLongTermMemoryPayload,\n+    background_tasks=Depends(get_background_tasks),\n ):\n     \"\"\"\n     Create a long-term memory\n \n     Args:\n         payload: Long-term memory payload\n+        background_tasks: DocketBackgroundTasks instance (injected automatically)\n \n     Returns:\n         Acknowledgement response\n     \"\"\"\n-    redis = get_redis_conn()\n-\n     if not settings.long_term_memory:\n         raise HTTPException(status_code=400, detail=\"Long-term memory is disabled\")\n \n-    await long_term_memory.index_long_term_memories(\n-        redis=redis,\n+    await background_tasks.add_task(\n+        long_term_memory.index_long_term_memories,\n         memories=payload.memories,\n-        background_tasks=background_tasks,\n     )\n     return AckResponse(status=\"ok\")\n "
    },
    {
      "filename": "agent_memory_server/config.py",
      "status": "modified",
      "patch": "@@ -30,5 +30,9 @@ class Settings(BaseSettings):\n     redisvl_index_name: str = \"memory\"\n     redisvl_index_prefix: str = \"memory\"\n \n+    # Docket settings\n+    docket_name: str = \"memory-server\"\n+    use_docket: bool = True\n+\n \n settings = Settings()"
    },
    {
      "filename": "agent_memory_server/dependencies.py",
      "status": "added",
      "patch": "@@ -0,0 +1,35 @@\n+from collections.abc import Callable\n+from typing import Any\n+\n+from fastapi import BackgroundTasks\n+\n+from agent_memory_server.config import settings\n+\n+\n+class DocketBackgroundTasks(BackgroundTasks):\n+    \"\"\"A BackgroundTasks implementation that uses Docket.\"\"\"\n+\n+    async def add_task(\n+        self, func: Callable[..., Any], *args: Any, **kwargs: Any\n+    ) -> None:\n+        \"\"\"Run tasks either directly or through Docket\"\"\"\n+        from docket import Docket\n+\n+        if settings.use_docket:\n+            async with Docket(\n+                name=settings.docket_name,\n+                url=settings.redis_url,\n+            ) as docket:\n+                # Schedule task through Docket\n+                await docket.add(func)(*args, **kwargs)\n+        else:\n+            await func(*args, **kwargs)\n+\n+\n+def get_background_tasks() -> DocketBackgroundTasks:\n+    \"\"\"\n+    Dependency function that returns a DocketBackgroundTasks instance.\n+\n+    This is used by API endpoints to inject a consistent background tasks object.\n+    \"\"\"\n+    return DocketBackgroundTasks()"
    },
    {
      "filename": "agent_memory_server/docket_tasks.py",
      "status": "added",
      "patch": "@@ -0,0 +1,43 @@\n+\"\"\"\n+Background task management using Docket.\n+\"\"\"\n+\n+import logging\n+\n+from docket import Docket\n+\n+from agent_memory_server.config import settings\n+from agent_memory_server.long_term_memory import (\n+    extract_memory_structure,\n+    index_long_term_memories,\n+)\n+from agent_memory_server.summarization import summarize_session\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+# Register functions in the task collection for the CLI worker\n+task_collection = [\n+    extract_memory_structure,\n+    summarize_session,\n+    index_long_term_memories,\n+]\n+\n+\n+async def register_tasks() -> None:\n+    \"\"\"Register all task functions with Docket.\"\"\"\n+    if not settings.use_docket:\n+        logger.info(\"Docket is disabled, skipping task registration\")\n+        return\n+\n+    # Initialize Docket client\n+    async with Docket(\n+        name=settings.docket_name,\n+        url=settings.redis_url,\n+    ) as docket:\n+        # Register all tasks\n+        for task in task_collection:\n+            docket.register(task)\n+\n+        logger.info(f\"Registered {len(task_collection)} background tasks with Docket\")"
    },
    {
      "filename": "agent_memory_server/long_term_memory.py",
      "status": "modified",
      "patch": "@@ -3,11 +3,11 @@\n from functools import reduce\n \n import nanoid\n-from fastapi import BackgroundTasks\n from redis.asyncio import Redis\n from redisvl.query import VectorQuery, VectorRangeQuery\n from redisvl.utils.vectorize import OpenAITextVectorizer\n \n+from agent_memory_server.dependencies import get_background_tasks\n from agent_memory_server.extraction import handle_extraction\n from agent_memory_server.filters import (\n     CreatedAt,\n@@ -25,6 +25,7 @@\n )\n from agent_memory_server.utils import (\n     Keys,\n+    get_redis_conn,\n     get_search_index,\n     safe_get,\n )\n@@ -33,11 +34,10 @@\n logger = logging.getLogger(__name__)\n \n \n-async def extract_memory_structure(\n-    redis: Redis, _id: str, text: str, namespace: str | None\n-):\n+async def extract_memory_structure(_id: str, text: str, namespace: str | None):\n+    redis = get_redis_conn()\n+\n     # Process messages for topic/entity extraction\n-    # TODO: Move into background task.\n     topics, entities = await handle_extraction(text)\n \n     # Convert lists to comma-separated strings for TAG fields\n@@ -65,14 +65,13 @@ async def compact_long_term_memories(redis: Redis) -> None:\n \n \n async def index_long_term_memories(\n-    redis: Redis,\n     memories: list[LongTermMemory],\n-    background_tasks: BackgroundTasks,\n ) -> None:\n     \"\"\"\n     Index long-term memories in Redis for search\n     \"\"\"\n-\n+    redis = get_redis_conn()\n+    background_tasks = get_background_tasks()\n     vectorizer = OpenAITextVectorizer()\n     embeddings = await vectorizer.aembed_many(\n         [memory.text for memory in memories],\n@@ -100,8 +99,8 @@ async def index_long_term_memories(\n                 },\n             )\n \n-            background_tasks.add_task(\n-                extract_memory_structure, redis, id_, memory.text, memory.namespace\n+            await background_tasks.add_task(\n+                extract_memory_structure, id_, memory.text, memory.namespace\n             )\n \n         await pipe.execute()"
    },
    {
      "filename": "agent_memory_server/main.py",
      "status": "modified",
      "patch": "@@ -1,4 +1,5 @@\n import os\n+import sys\n from contextlib import asynccontextmanager\n \n import uvicorn\n@@ -7,6 +8,7 @@\n from agent_memory_server import utils\n from agent_memory_server.api import router as memory_router\n from agent_memory_server.config import settings\n+from agent_memory_server.docket_tasks import register_tasks\n from agent_memory_server.healthcheck import router as health_router\n from agent_memory_server.llms import MODEL_CONFIGS, ModelProvider\n from agent_memory_server.logging import configure_logging, get_logger\n@@ -87,6 +89,20 @@ async def lifespan(app: FastAPI):\n             logger.error(f\"Failed to ensure RediSearch index: {e}\")\n             raise\n \n+    # Initialize Docket for background tasks if enabled\n+    if settings.use_docket:\n+        try:\n+            await register_tasks()\n+            logger.info(\"Initialized Docket for background tasks\")\n+            logger.info(\"To run the worker, use one of these methods:\")\n+            logger.info(\n+                \"1. CLI: docket worker --tasks agent_memory_server.docket_tasks:task_collection\"\n+            )\n+            logger.info(\"2. Python: python -m agent_memory_server.worker\")\n+        except Exception as e:\n+            logger.error(f\"Failed to initialize Docket: {e}\")\n+            raise\n+\n     # Show available models\n     openai_models = [\n         model\n@@ -138,6 +154,31 @@ def on_start_logger(port: int):\n \n # Run the application\n if __name__ == \"__main__\":\n-    port = int(os.environ.get(\"PORT\", \"8000\"))\n+    # Parse command line arguments for port\n+    port = settings.port\n+\n+    # Check if --port argument is provided\n+    if \"--port\" in sys.argv:\n+        try:\n+            port_index = sys.argv.index(\"--port\") + 1\n+            if port_index < len(sys.argv):\n+                port = int(sys.argv[port_index])\n+                print(f\"Using port from command line: {port}\")\n+        except (ValueError, IndexError):\n+            # If conversion fails or index out of bounds, use default\n+            print(f\"Invalid port argument, using default: {port}\")\n+    else:\n+        print(f\"No port argument provided, using default: {port}\")\n+\n+    # Explicitly unset the PORT environment variable if it exists\n+    if \"PORT\" in os.environ:\n+        port_val = os.environ.pop(\"PORT\")\n+        print(f\"Removed environment variable PORT={port_val}\")\n+\n     on_start_logger(port)\n-    uvicorn.run(\"agent_memory_server.main:app\", host=\"0.0.0.0\", port=port, reload=False)\n+    uvicorn.run(\n+        app,  # Using the app instance directly\n+        host=\"0.0.0.0\",\n+        port=port,\n+        reload=False,\n+    )"
    },
    {
      "filename": "agent_memory_server/mcp.py",
      "status": "modified",
      "patch": "@@ -2,7 +2,7 @@\n import logging\n import sys\n \n-from fastapi import BackgroundTasks, HTTPException\n+from fastapi import HTTPException\n from mcp.server.fastmcp import FastMCP\n from mcp.server.fastmcp.prompts import base\n from mcp.types import TextContent\n@@ -13,6 +13,7 @@\n     search_long_term_memory as core_search_long_term_memory,\n )\n from agent_memory_server.config import settings\n+from agent_memory_server.dependencies import get_background_tasks\n from agent_memory_server.models import (\n     AckResponse,\n     CreateLongTermMemoryPayload,\n@@ -75,7 +76,7 @@ async def create_long_term_memories(\n         An acknowledgement response indicating success\n     \"\"\"\n     return await core_create_long_term_memory(\n-        payload, background_tasks=BackgroundTasks()\n+        payload, background_tasks=get_background_tasks()\n     )\n \n "
    },
    {
      "filename": "agent_memory_server/messages.py",
      "status": "modified",
      "patch": "@@ -2,11 +2,11 @@\n import logging\n import time\n \n-from fastapi import BackgroundTasks\n from redis import WatchError\n from redis.asyncio import Redis\n \n from agent_memory_server.config import settings\n+from agent_memory_server.dependencies import DocketBackgroundTasks\n from agent_memory_server.long_term_memory import index_long_term_memories\n from agent_memory_server.models import (\n     LongTermMemory,\n@@ -87,18 +87,16 @@ async def set_session_memory(\n     redis: Redis,\n     session_id: str,\n     memory: SessionMemory,\n-    background_tasks: BackgroundTasks,\n+    background_tasks: DocketBackgroundTasks,\n ):\n     \"\"\"\n     Create or update a session's memory\n \n-    TODO: This shouldn't need BackgroundTasks.\n-\n     Args:\n         redis: The Redis client\n         session_id: The session ID\n         memory: The session memory to set\n-        background_tasks: The background tasks to add the summarization task to\n+        background_tasks: Background tasks instance\n     \"\"\"\n     sessions_key = Keys.sessions_key(namespace=memory.namespace)\n     messages_key = Keys.messages_key(session_id, namespace=memory.namespace)\n@@ -127,32 +125,28 @@ async def set_session_memory(\n     # Check if window size is exceeded\n     current_size = await redis.llen(messages_key)  # type: ignore\n     if current_size > settings.window_size:\n-        # Handle summarization in background\n-        background_tasks.add_task(\n+        # Add summarization task\n+        await background_tasks.add_task(\n             summarize_session,\n-            redis,\n             session_id,\n             settings.generation_model,\n             settings.window_size,\n         )\n \n     # If long-term memory is enabled, index messages\n-    # TODO: Use a distributed task queue\n-    # TODO: Allow strategies for long-term memory: indexing\n-    #       messages vs. extracting memories from messages, etc.\n     if settings.long_term_memory:\n-        background_tasks.add_task(\n+        memories = [\n+            LongTermMemory(\n+                session_id=session_id,\n+                text=f\"{msg.role}: {msg.content}\",\n+                namespace=memory.namespace,\n+            )\n+            for msg in memory.messages\n+        ]\n+\n+        await background_tasks.add_task(\n             index_long_term_memories,\n-            redis,\n-            [\n-                LongTermMemory(\n-                    session_id=session_id,\n-                    text=f\"{msg.role}: {msg.content}\",\n-                    namespace=memory.namespace,\n-                )\n-                for msg in memory.messages\n-            ],\n-            background_tasks,\n+            memories,\n         )\n \n "
    },
    {
      "filename": "agent_memory_server/summarization.py",
      "status": "modified",
      "patch": "@@ -3,7 +3,6 @@\n \n import tiktoken\n from redis import WatchError\n-from redis.asyncio import Redis\n \n from agent_memory_server.config import settings\n from agent_memory_server.llms import (\n@@ -12,7 +11,7 @@\n     get_model_config,\n )\n from agent_memory_server.models import MemoryMessage\n-from agent_memory_server.utils import Keys, get_model_client\n+from agent_memory_server.utils import Keys, get_model_client, get_redis_conn\n \n \n logger = logging.getLogger(__name__)\n@@ -110,7 +109,6 @@ async def _incremental_summary(\n \n \n async def summarize_session(\n-    redis: Redis,\n     session_id: str,\n     model: str,\n     window_size: int,\n@@ -132,6 +130,7 @@ async def summarize_session(\n         client: The client wrapper (OpenAI or Anthropic)\n         redis_conn: Redis connection\n     \"\"\"\n+    redis = get_redis_conn()\n     client = await get_model_client(settings.generation_model)\n \n     messages_key = Keys.messages_key(session_id)"
    },
    {
      "filename": "agent_memory_server/worker.py",
      "status": "added",
      "patch": "@@ -0,0 +1,111 @@\n+\"\"\"\n+Run the Docket worker directly from Python.\n+\n+This module provides a way to run the background task worker in-process\n+instead of using the CLI command.\n+\n+Usage:\n+    python -m agent_memory_server.worker\n+\"\"\"\n+\n+import asyncio\n+import signal\n+import sys\n+from datetime import timedelta\n+\n+from docket import Docket, Worker\n+\n+from agent_memory_server.config import settings\n+from agent_memory_server.docket_tasks import task_collection\n+from agent_memory_server.logging import configure_logging, get_logger\n+\n+\n+configure_logging()\n+logger = get_logger(__name__)\n+\n+\n+async def run_worker(concurrency: int = 10, redelivery_timeout: int = 30):\n+    \"\"\"\n+    Run the Docket worker in Python.\n+\n+    Args:\n+        concurrency: Number of tasks to process concurrently\n+        redelivery_timeout: Seconds to wait before redelivering a task to another worker\n+    \"\"\"\n+    if not settings.use_docket:\n+        logger.error(\"Docket is disabled in settings. Cannot run worker.\")\n+        return None\n+\n+    logger.info(f\"Starting Docket worker for {settings.docket_name}\")\n+    logger.info(\n+        f\"Concurrency: {concurrency}, Redelivery timeout: {redelivery_timeout}s\"\n+    )\n+\n+    # Create a signal handler to gracefully shut down\n+    shutdown_event = asyncio.Event()\n+\n+    def handle_signal(sig, frame):\n+        logger.info(f\"Received signal {sig}, shutting down...\")\n+        shutdown_event.set()\n+\n+    # Register signal handlers\n+    signal.signal(signal.SIGINT, handle_signal)\n+    signal.signal(signal.SIGTERM, handle_signal)\n+\n+    try:\n+        # Initialize Docket client\n+        async with Docket(\n+            name=settings.docket_name,\n+            url=settings.redis_url,\n+        ) as docket:\n+            # Register all tasks\n+            for task in task_collection:\n+                docket.register(task)\n+\n+            logger.info(f\"Registered {len(task_collection)} tasks\")\n+\n+            # Create and run the worker\n+            async with Worker(\n+                docket,\n+                concurrency=concurrency,\n+                redelivery_timeout=timedelta(seconds=redelivery_timeout),\n+            ) as worker:\n+                # Run until shutdown is requested\n+                await worker.run_forever()\n+\n+    except Exception as e:\n+        logger.error(f\"Error running worker: {e}\")\n+        return 1\n+\n+    logger.info(\"Worker shut down gracefully\")\n+    return 0\n+\n+\n+def main():\n+    \"\"\"Command line entry point\"\"\"\n+    # Parse command line arguments\n+    concurrency = 10\n+    redelivery_timeout = 30\n+\n+    args = sys.argv[1:]\n+    if \"--concurrency\" in args:\n+        try:\n+            idx = args.index(\"--concurrency\")\n+            concurrency = int(args[idx + 1])\n+        except (ValueError, IndexError):\n+            pass\n+\n+    if \"--redelivery-timeout\" in args:\n+        try:\n+            idx = args.index(\"--redelivery-timeout\")\n+            redelivery_timeout = int(args[idx + 1])\n+        except (ValueError, IndexError):\n+            pass\n+\n+    return asyncio.run(\n+        run_worker(concurrency=concurrency, redelivery_timeout=redelivery_timeout)\n+    )\n+\n+\n+if __name__ == \"__main__\":\n+    sys.exit(main())"
    },
    {
      "filename": "pyproject.toml",
      "status": "modified",
      "patch": "@@ -5,31 +5,31 @@ build-backend = \"hatchling.build\"\n [project]\n name = \"agent-memory-server\"\n version = \"0.2.0\"\n-description = \"A Redis-powered memory server built for AI agents and applications.\"\n+description = \"A Memory Server for LLM Agents and Applications\"\n readme = \"README.md\"\n requires-python = \">=3.12,<3.13\"\n license = { text = \"MIT\" }\n authors = [{ name = \"Andrew Brookins\", email = \"andrew.brookins@redis.com\" }]\n dependencies = [\n+    \"accelerate>=1.6.0\",\n+    \"anthropic>=0.15.0\",\n+    \"bertopic<0.17.0,>=0.16.4\",\n     \"fastapi>=0.115.11\",\n-    \"uvicorn>=0.24.0\",\n-    \"redis>=5.0.1\",\n+    \"mcp>=1.6.0\",\n+    \"nanoid>=2.0.0\",\n+    \"numba>=0.60.0\",\n+    \"numpy>=2.1.0\",\n     \"openai>=1.3.7\",\n-    \"anthropic>=0.15.0\",\n     \"pydantic>=2.5.2\",\n-    \"python-dotenv>=1.0.0\",\n-    \"tiktoken>=0.5.1\",\n-    \"numpy>=2.1.0\",\n     \"pydantic-settings>=2.8.1\",\n-    \"bertopic>=0.16.4,<0.17.0\",\n-    \"structlog>=25.2.0\",\n-    \"transformers>=4.30.0,<=4.50.3\",\n-    \"numba>=0.60.0\",\n-    \"nanoid>=2.0.0\",\n-    \"mcp>=1.6.0\",\n-    \"sentence-transformers>=3.4.1\",\n-    \"accelerate>=1.6.0\",\n+    \"python-dotenv>=1.0.0\",\n+    \"pydocket>=0.6.3\",\n     \"redisvl>=0.5.1\",\n+    \"sentence-transformers>=3.4.1\",\n+    \"structlog>=25.2.0\",\n+    \"tiktoken>=0.5.1\",\n+    \"transformers<=4.50.3,>=4.30.0\",\n+    \"uvicorn>=0.24.0\",\n ]\n \n [tool.hatch.build.targets.wheel]"
    },
    {
      "filename": "start_worker.sh",
      "status": "added",
      "patch": "@@ -0,0 +1 @@\n+worker_command=\"docket worker --tasks agent_memory_server.docket_tasks:task_collection\""
    },
    {
      "filename": "tests/conftest.py",
      "status": "modified",
      "patch": "@@ -6,14 +6,15 @@\n \n import pytest\n from dotenv import load_dotenv\n-from fastapi import BackgroundTasks, FastAPI\n+from fastapi import FastAPI\n from httpx import ASGITransport, AsyncClient\n from redis import Redis\n from redis.asyncio import ConnectionPool, Redis as AsyncRedis\n from testcontainers.compose import DockerCompose\n \n from agent_memory_server.api import router as memory_router\n from agent_memory_server.config import settings\n+from agent_memory_server.dependencies import DocketBackgroundTasks, get_background_tasks\n from agent_memory_server.healthcheck import router as health_router\n from agent_memory_server.llms import OpenAIClientWrapper\n from agent_memory_server.messages import (\n@@ -105,7 +106,6 @@ async def session(use_test_redis_connection, async_redis_client):\n     session_id = \"test-session\"\n \n     await index_long_term_memories(\n-        async_redis_client,\n         [\n             LongTermMemory(\n                 session_id=session_id,\n@@ -118,7 +118,6 @@ async def session(use_test_redis_connection, async_redis_client):\n                 namespace=\"test-namespace\",\n             ),\n         ],\n-        background_tasks=BackgroundTasks(),\n     )\n \n     # Add messages to session memory\n@@ -137,7 +136,7 @@ async def session(use_test_redis_connection, async_redis_client):\n             tokens=150,\n             namespace=\"test-namespace\",\n         ),\n-        background_tasks=BackgroundTasks(),\n+        background_tasks=DocketBackgroundTasks(),\n     )\n \n     return session_id\n@@ -243,7 +242,10 @@ def pytest_collection_modifyitems(\n             item.add_marker(skip_api)\n \n \n-MockBackgroundTasks = mock.Mock(name=\"BackgroundTasks\", spec=BackgroundTasks)\n+@pytest.fixture()\n+def mock_background_tasks():\n+    \"\"\"Create a mock DocketBackgroundTasks instance\"\"\"\n+    return mock.Mock(name=\"DocketBackgroundTasks\", spec=DocketBackgroundTasks)\n \n \n @pytest.fixture()\n@@ -259,16 +261,15 @@ def app(use_test_redis_connection):\n \n \n @pytest.fixture()\n-def app_with_mock_background_tasks(use_test_redis_connection):\n+def app_with_mock_background_tasks(use_test_redis_connection, mock_background_tasks):\n     \"\"\"Create a test FastAPI app with routers\"\"\"\n     app = FastAPI()\n \n     # Include routers\n     app.include_router(health_router)\n     app.include_router(memory_router)\n \n-    mock_background_tasks = MockBackgroundTasks()\n-    app.dependency_overrides[BackgroundTasks] = lambda: mock_background_tasks\n+    app.dependency_overrides[get_background_tasks] = lambda: mock_background_tasks\n \n     return app\n "
    },
    {
      "filename": "tests/test_api.py",
      "status": "modified",
      "patch": "@@ -123,8 +123,11 @@ async def test_put_memory(self, client):\n \n     @pytest.mark.requires_api_keys\n     @pytest.mark.asyncio\n-    async def test_put_memory_stores_messages_in_long_term_memory(self, client):\n+    async def test_put_memory_stores_messages_in_long_term_memory(\n+        self, client_with_mock_background_tasks, mock_background_tasks\n+    ):\n         \"\"\"Test the put_memory endpoint\"\"\"\n+        client = client_with_mock_background_tasks\n         payload = {\n             \"messages\": [\n                 {\"role\": \"user\", \"content\": \"Hello\"},\n@@ -133,12 +136,8 @@ async def test_put_memory_stores_messages_in_long_term_memory(self, client):\n             \"context\": \"Previous context\",\n         }\n         mock_settings = Settings(long_term_memory=True)\n-        mock_add_task = MagicMock()\n \n-        with (\n-            patch(\"agent_memory_server.api.settings\", mock_settings),\n-            patch(\"agent_memory_server.api.BackgroundTasks.add_task\", mock_add_task),\n-        ):\n+        with patch(\"agent_memory_server.api.settings\", mock_settings):\n             response = await client.put(\"/sessions/test-session/memory\", json=payload)\n \n         assert response.status_code == 200\n@@ -148,15 +147,21 @@ async def test_put_memory_stores_messages_in_long_term_memory(self, client):\n         assert data[\"status\"] == \"ok\"\n \n         # Check that background tasks were called\n-        assert mock_add_task.call_count == 1\n+        assert mock_background_tasks.add_task.call_count == 1\n \n         # Check that the last call was for long-term memory indexing\n-        assert mock_add_task.call_args_list[-1][0][0] == index_long_term_memories\n+        assert (\n+            mock_background_tasks.add_task.call_args_list[-1][0][0]\n+            == index_long_term_memories\n+        )\n \n     @pytest.mark.requires_api_keys\n     @pytest.mark.asyncio\n-    async def test_post_memory_compacts_long_conversation(self, client):\n+    async def test_post_memory_compacts_long_conversation(\n+        self, client_with_mock_background_tasks, mock_background_tasks\n+    ):\n         \"\"\"Test the post_memory endpoint\"\"\"\n+        client = client_with_mock_background_tasks\n         payload = {\n             \"messages\": [\n                 {\"role\": \"user\", \"content\": \"Hello\"},\n@@ -165,12 +170,9 @@ async def test_post_memory_compacts_long_conversation(self, client):\n             \"context\": \"Previous context\",\n         }\n         mock_settings = Settings(window_size=1, long_term_memory=False)\n-        mock_add_task = MagicMock()\n+        MagicMock()\n \n-        with (\n-            patch(\"agent_memory_server.api.messages.settings\", mock_settings),\n-            patch(\"agent_memory_server.api.BackgroundTasks.add_task\", mock_add_task),\n-        ):\n+        with patch(\"agent_memory_server.api.messages.settings\", mock_settings):\n             response = await client.put(\"/sessions/test-session/memory\", json=payload)\n \n         assert response.status_code == 200\n@@ -180,10 +182,12 @@ async def test_post_memory_compacts_long_conversation(self, client):\n         assert data[\"status\"] == \"ok\"\n \n         # Check that background tasks were called\n-        assert mock_add_task.call_count == 1\n+        assert mock_background_tasks.add_task.call_count == 1\n \n         # Check that the last call was for compaction\n-        assert mock_add_task.call_args_list[-1][0][0] == summarize_session\n+        assert (\n+            mock_background_tasks.add_task.call_args_list[-1][0][0] == summarize_session\n+        )\n \n     @pytest.mark.asyncio\n     async def test_delete_memory(self, client, session):"
    },
    {
      "filename": "tests/test_long_term_memory.py",
      "status": "modified",
      "patch": "@@ -5,7 +5,6 @@\n import nanoid\n import numpy as np\n import pytest\n-from fastapi import BackgroundTasks\n from redis.commands.search.document import Document\n \n from agent_memory_server.filters import SessionId\n@@ -27,12 +26,14 @@ async def test_index_memories(\n             LongTermMemory(text=\"France is a country in Europe\", session_id=session),\n         ]\n \n-        mock_vector = np.array(\n-            [[0.1, 0.2, 0.3, 0.4], [0.1, 0.2, 0.3, 0.4]], dtype=np.float32\n-        )\n+        # Create two separate embedding vectors\n+        mock_vectors = [\n+            np.array([0.1, 0.2, 0.3, 0.4], dtype=np.float32).tobytes(),\n+            np.array([0.5, 0.6, 0.7, 0.8], dtype=np.float32).tobytes(),\n+        ]\n \n         mock_vectorizer = MagicMock()\n-        mock_vectorizer.aembed_many = AsyncMock(return_value=mock_vector)\n+        mock_vectorizer.aembed_many = AsyncMock(return_value=mock_vectors)\n \n         mock_async_redis_client.hset = AsyncMock()\n \n@@ -41,9 +42,7 @@ async def test_index_memories(\n             return_value=mock_vectorizer,\n         ):\n             await index_long_term_memories(\n-                mock_async_redis_client,\n                 long_term_memories,\n-                background_tasks=BackgroundTasks(),\n             )\n \n         # Check that create_embedding was called with the right arguments\n@@ -55,7 +54,7 @@ async def test_index_memories(\n         )\n \n         # Verify one of the calls to make sure the data is correct\n-        for call in mock_async_redis_client.hset.call_args_list:\n+        for i, call in enumerate(mock_async_redis_client.hset.call_args_list):\n             args, kwargs = call\n \n             # Check that the key starts with the memory key prefix\n@@ -64,13 +63,13 @@ async def test_index_memories(\n             # Check that the mapping contains the right keys\n             mapping = kwargs[\"mapping\"]\n             assert mapping == {\n-                \"text\": long_term_memories[0].text,\n-                \"id_\": long_term_memories[0].id_,\n-                \"session_id\": long_term_memories[0].session_id,\n-                \"user_id\": long_term_memories[0].user_id,\n-                \"last_accessed\": long_term_memories[0].last_accessed,\n-                \"created_at\": long_term_memories[0].created_at,\n-                \"vector\": mock_vector.tobytes(),\n+                \"text\": long_term_memories[i].text,\n+                \"id_\": long_term_memories[i].id_,\n+                \"session_id\": long_term_memories[i].session_id,\n+                \"user_id\": long_term_memories[i].user_id,\n+                \"last_accessed\": long_term_memories[i].last_accessed,\n+                \"created_at\": long_term_memories[i].created_at,\n+                \"vector\": mock_vectors[i],\n             }\n \n     @pytest.mark.asyncio\n@@ -168,11 +167,13 @@ async def test_search_messages(self, async_redis_client):\n             LongTermMemory(text=\"France is a country in Europe\", session_id=\"123\"),\n         ]\n \n-        await index_long_term_memories(\n-            async_redis_client,\n-            long_term_memories,\n-            background_tasks=BackgroundTasks(),\n-        )\n+        with mock.patch(\n+            \"agent_memory_server.long_term_memory.get_redis_conn\",\n+            return_value=async_redis_client,\n+        ):\n+            await index_long_term_memories(\n+                long_term_memories,\n+            )\n \n         results = await search_long_term_memories(\n             \"What is the capital of France?\",\n@@ -195,11 +196,13 @@ async def test_search_messages_with_distance_threshold(self, async_redis_client)\n             LongTermMemory(text=\"France is a country in Europe\", session_id=\"123\"),\n         ]\n \n-        await index_long_term_memories(\n-            async_redis_client,\n-            long_term_memories,\n-            background_tasks=BackgroundTasks(),\n-        )\n+        with mock.patch(\n+            \"agent_memory_server.long_term_memory.get_redis_conn\",\n+            return_value=async_redis_client,\n+        ):\n+            await index_long_term_memories(\n+                long_term_memories,\n+            )\n \n         results = await search_long_term_memories(\n             \"What is the capital of France?\","
    },
    {
      "filename": "tests/test_messages.py",
      "status": "modified",
      "patch": "@@ -160,6 +160,7 @@ async def test_set_session_memory_window_size_exceeded(\n         mock_async_redis_client.pipeline = MagicMock(return_value=mock_pipeline)\n \n         mock_background_tasks = MagicMock()\n+        mock_background_tasks.add_task = AsyncMock()\n \n         memory = SessionMemory(\n             messages=[MemoryMessage(role=\"user\", content=\"Hello\")],\n@@ -181,7 +182,6 @@ async def test_set_session_memory_window_size_exceeded(\n         # Verify summarization task was added\n         mock_background_tasks.add_task.assert_called_with(\n             summarize_session,\n-            mock_async_redis_client,\n             \"test-session\",\n             \"gpt-4o-mini\",\n             20,\n@@ -205,6 +205,7 @@ async def test_set_session_memory_with_long_term_memory(\n         mock_async_redis_client.pipeline = MagicMock(return_value=mock_pipeline)\n \n         mock_background_tasks = MagicMock()\n+        mock_background_tasks.add_task = AsyncMock()\n \n         memory = SessionMemory(\n             messages=[MemoryMessage(role=\"user\", content=\"Hello\")],\n@@ -228,9 +229,7 @@ async def test_set_session_memory_with_long_term_memory(\n         assert mock_background_tasks.add_task.call_args_list == [\n             call(\n                 index_long_term_memories,\n-                mock_async_redis_client,\n                 [LongTermMemory(session_id=\"test-session\", text=\"user: Hello\")],\n-                mock_background_tasks,\n             ),\n         ]\n "
    },
    {
      "filename": "tests/test_summarization.py",
      "status": "modified",
      "patch": "@@ -111,13 +111,18 @@ async def test_summarize_session(\n \n         mock_summarization.return_value = (\"New summary\", 300)\n \n-        with patch(\n-            \"agent_memory_server.summarization.get_model_client\"\n-        ) as mock_get_model_client:\n+        with (\n+            patch(\n+                \"agent_memory_server.summarization.get_model_client\"\n+            ) as mock_get_model_client,\n+            patch(\n+                \"agent_memory_server.summarization.get_redis_conn\",\n+                return_value=mock_async_redis_client,\n+            ),\n+        ):\n             mock_get_model_client.return_value = mock_openai_client\n \n             await summarize_session(\n-                mock_async_redis_client,\n                 session_id,\n                 model,\n                 window_size,\n@@ -178,12 +183,15 @@ async def test_handle_summarization_no_messages(\n         pipeline_mock.lpop = AsyncMock(return_value=True)\n         pipeline_mock.execute = AsyncMock(return_value=True)\n \n-        await summarize_session(\n-            mock_async_redis_client,\n-            session_id,\n-            model,\n-            window_size,\n-        )\n+        with patch(\n+            \"agent_memory_server.summarization.get_redis_conn\",\n+            return_value=mock_async_redis_client,\n+        ):\n+            await summarize_session(\n+                session_id,\n+                model,\n+                window_size,\n+            )\n \n         assert mock_summarization.call_count == 0\n         assert pipeline_mock.lrange.call_count == 0"
    },
    {
      "filename": "uv.lock",
      "status": "modified",
      "patch": "@@ -35,8 +35,8 @@ dependencies = [\n     { name = \"openai\" },\n     { name = \"pydantic\" },\n     { name = \"pydantic-settings\" },\n+    { name = \"pydocket\" },\n     { name = \"python-dotenv\" },\n-    { name = \"redis\" },\n     { name = \"redisvl\" },\n     { name = \"sentence-transformers\" },\n     { name = \"structlog\" },\n@@ -68,8 +68,8 @@ requires-dist = [\n     { name = \"openai\", specifier = \">=1.3.7\" },\n     { name = \"pydantic\", specifier = \">=2.5.2\" },\n     { name = \"pydantic-settings\", specifier = \">=2.8.1\" },\n+    { name = \"pydocket\", specifier = \">=0.6.3\" },\n     { name = \"python-dotenv\", specifier = \">=1.0.0\" },\n-    { name = \"redis\", specifier = \">=5.0.1\" },\n     { name = \"redisvl\", specifier = \">=0.5.1\" },\n     { name = \"sentence-transformers\", specifier = \">=3.4.1\" },\n     { name = \"structlog\", specifier = \">=25.2.0\" },\n@@ -213,6 +213,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl\", hash = \"sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2\", size = 98188 },\n ]\n \n+[[package]]\n+name = \"cloudpickle\"\n+version = \"3.1.1\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/52/39/069100b84d7418bc358d81669d5748efb14b9cceacd2f9c75f550424132f/cloudpickle-3.1.1.tar.gz\", hash = \"sha256:b216fa8ae4019d5482a8ac3c95d8f6346115d8835911fd4aefd1a445e4242c64\", size = 22113 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/7e/e8/64c37fadfc2816a7701fa8a6ed8d87327c7d54eacfbfb6edab14a2f2be75/cloudpickle-3.1.1-py3-none-any.whl\", hash = \"sha256:c8c5a44295039331ee9dad40ba100a9c7297b6f988e50e87ccdf3765a668350e\", size = 20992 },\n+]\n+\n [[package]]\n name = \"colorama\"\n version = \"0.4.6\"\n@@ -234,6 +243,18 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl\", hash = \"sha256:612ee75c546f53e92e70049c9dbfcc18c935a2b9a53b66085ce9ef6a6e5c0934\", size = 46018 },\n ]\n \n+[[package]]\n+name = \"deprecated\"\n+version = \"1.2.18\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"wrapt\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/98/97/06afe62762c9a8a86af0cfb7bfdab22a43ad17138b07af5b1a58442690a2/deprecated-1.2.18.tar.gz\", hash = \"sha256:422b6f6d859da6f2ef57857761bfb392480502a64c3028ca9bbe86085d72115d\", size = 2928744 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/6e/c6/ac0b6c1e2d138f1002bcf799d330bd6d85084fece321e662a14223794041/Deprecated-1.2.18-py2.py3-none-any.whl\", hash = \"sha256:bd5011788200372a32418f888e326a09ff80d0214bd961147cfed01b5c018eec\", size = 9998 },\n+]\n+\n [[package]]\n name = \"distlib\"\n version = \"0.3.9\"\n@@ -417,6 +438,18 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl\", hash = \"sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3\", size = 70442 },\n ]\n \n+[[package]]\n+name = \"importlib-metadata\"\n+version = \"8.6.1\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"zipp\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/33/08/c1395a292bb23fd03bdf572a1357c5a733d3eecbab877641ceacab23db6e/importlib_metadata-8.6.1.tar.gz\", hash = \"sha256:310b41d755445d74569f993ccfc22838295d9fe005425094fad953d7f15c8580\", size = 55767 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/79/9d/0fb148dc4d6fa4a7dd1d8378168d9b4cd8d4560a6fbf6f0121c5fc34eb68/importlib_metadata-8.6.1-py3-none-any.whl\", hash = \"sha256:02a89390c1e15fdfdc0d7c6b25cb3e62650d0494005c97d6f148bf5b9787525e\", size = 26971 },\n+]\n+\n [[package]]\n name = \"iniconfig\"\n version = \"2.1.0\"\n@@ -512,6 +545,18 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/d0/81/e66fc86539293282fd9cb7c9417438e897f369e79ffb62e1ae5e5154d4dd/llvmlite-0.44.0-cp313-cp313-win_amd64.whl\", hash = \"sha256:2fb7c4f2fb86cbae6dca3db9ab203eeea0e22d73b99bc2341cdf9de93612e930\", size = 30331193 },\n ]\n \n+[[package]]\n+name = \"markdown-it-py\"\n+version = \"3.0.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"mdurl\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/38/71/3b932df36c1a044d397a1f92d1cf91ee0a503d91e470cbd670aa66b07ed0/markdown-it-py-3.0.0.tar.gz\", hash = \"sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\", size = 74596 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl\", hash = \"sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1\", size = 87528 },\n+]\n+\n [[package]]\n name = \"markupsafe\"\n version = \"3.0.2\"\n@@ -569,6 +614,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/10/30/20a7f33b0b884a9d14dd3aa94ff1ac9da1479fe2ad66dd9e2736075d2506/mcp-1.6.0-py3-none-any.whl\", hash = \"sha256:7bd24c6ea042dbec44c754f100984d186620d8b841ec30f1b19eda9b93a634d0\", size = 76077 },\n ]\n \n+[[package]]\n+name = \"mdurl\"\n+version = \"0.1.2\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/d6/54/cfe61301667036ec958cb99bd3efefba235e65cdeb9c84d24a8293ba1d90/mdurl-0.1.2.tar.gz\", hash = \"sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\", size = 8729 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl\", hash = \"sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8\", size = 9979 },\n+]\n+\n [[package]]\n name = \"ml-dtypes\"\n version = \"0.4.1\"\n@@ -826,6 +880,60 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/c4/f7/049e85faf6a000890e5ca0edca8e9183f8a43c9e7bba869cad871da0caba/openai-1.71.0-py3-none-any.whl\", hash = \"sha256:e1c643738f1fff1af52bce6ef06a7716c95d089281e7011777179614f32937aa\", size = 598975 },\n ]\n \n+[[package]]\n+name = \"opentelemetry-api\"\n+version = \"1.32.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"deprecated\" },\n+    { name = \"importlib-metadata\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/7b/34/e701d77900123af17a11dbaf0c9f527fa7ef94b8f02b2c55bed94477890a/opentelemetry_api-1.32.0.tar.gz\", hash = \"sha256:2623280c916f9b19cad0aa4280cb171265f19fd2909b0d47e4f06f7c83b02cb5\", size = 64134 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/fe/e8/d05fd19c1c7e7e230ab44c366791179fd64c843bc587c257a56e853893c5/opentelemetry_api-1.32.0-py3-none-any.whl\", hash = \"sha256:15df743c765078611f376037b0d9111ec5c1febf2ec9440cdd919370faa1ce55\", size = 65285 },\n+]\n+\n+[[package]]\n+name = \"opentelemetry-exporter-prometheus\"\n+version = \"0.53b0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"opentelemetry-api\" },\n+    { name = \"opentelemetry-sdk\" },\n+    { name = \"prometheus-client\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/e0/13/d1fe83281e40f050d04f45e6e865f36991e98d9c8f1c5f4614602af1431a/opentelemetry_exporter_prometheus-0.53b0.tar.gz\", hash = \"sha256:2d8dd0684b5229840974a85686028954a2b2170f5118cb36fa6497f11cb35f29\", size = 14948 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/18/f3/4f0e7e33dcb41317905db2933f9ea86ce728d5710cf4f60063ee9763d4d5/opentelemetry_exporter_prometheus-0.53b0-py3-none-any.whl\", hash = \"sha256:a202262aa96f1840e0ebff75bef5b11e6d84cafd0e6a0f82979cccda0cdcee3b\", size = 12950 },\n+]\n+\n+[[package]]\n+name = \"opentelemetry-sdk\"\n+version = \"1.32.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"opentelemetry-api\" },\n+    { name = \"opentelemetry-semantic-conventions\" },\n+    { name = \"typing-extensions\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/e8/0c/842aed73035cab0302ec70057f3180f4f023974d74bd9764ef3046f358fb/opentelemetry_sdk-1.32.0.tar.gz\", hash = \"sha256:5ff07fb371d1ab1189fa7047702e2e888b5403c5efcbb18083cae0d5aa5f58d2\", size = 161043 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/ee/6a/b8cb562234bd94bcf12ad3058ef7f31319b94a8df65130ce9cc2ff3c8d55/opentelemetry_sdk-1.32.0-py3-none-any.whl\", hash = \"sha256:ed252d035c22a15536c1f603ca089298daab60850fc2f5ddfa95d95cc1c043ea\", size = 118990 },\n+]\n+\n+[[package]]\n+name = \"opentelemetry-semantic-conventions\"\n+version = \"0.53b0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"deprecated\" },\n+    { name = \"opentelemetry-api\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/c2/c4/213d23239df175b420b74c6e25899c482701e6614822dc51f8c20dae7e2d/opentelemetry_semantic_conventions-0.53b0.tar.gz\", hash = \"sha256:05b7908e1da62d72f9bf717ed25c72f566fe005a2dd260c61b11e025f2552cf6\", size = 114343 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/7c/23/0bef11f394f828f910f32567d057f097dbaba23edf33114018a380a0d0bf/opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl\", hash = \"sha256:561da89f766ab51615c0e72b12329e0a1bc16945dbd62c8646ffc74e36a1edff\", size = 188441 },\n+]\n+\n [[package]]\n name = \"packaging\"\n version = \"24.2\"\n@@ -963,6 +1071,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/88/74/a88bf1b1efeae488a0c0b7bdf71429c313722d1fc0f377537fbe554e6180/pre_commit-4.2.0-py2.py3-none-any.whl\", hash = \"sha256:a009ca7205f1eb497d10b845e52c838a98b6cdd2102a6c8e4540e94ee75c58bd\", size = 220707 },\n ]\n \n+[[package]]\n+name = \"prometheus-client\"\n+version = \"0.21.1\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/62/14/7d0f567991f3a9af8d1cd4f619040c93b68f09a02b6d0b6ab1b2d1ded5fe/prometheus_client-0.21.1.tar.gz\", hash = \"sha256:252505a722ac04b0456be05c05f75f45d760c2911ffc45f2a06bcaed9f3ae3fb\", size = 78551 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/ff/c2/ab7d37426c179ceb9aeb109a85cda8948bb269b7561a0be870cc656eefe4/prometheus_client-0.21.1-py3-none-any.whl\", hash = \"sha256:594b45c410d6f4f8888940fe80b5cc2521b305a1fafe1c58609ef715a001f301\", size = 54682 },\n+]\n+\n [[package]]\n name = \"psutil\"\n version = \"7.0.0\"\n@@ -1048,6 +1165,35 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/0b/53/a64f03044927dc47aafe029c42a5b7aabc38dfb813475e0e1bf71c4a59d0/pydantic_settings-2.8.1-py3-none-any.whl\", hash = \"sha256:81942d5ac3d905f7f3ee1a70df5dfb62d5569c12f51a5a647defc1c3d9ee2e9c\", size = 30839 },\n ]\n \n+[[package]]\n+name = \"pydocket\"\n+version = \"0.6.3\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"cloudpickle\" },\n+    { name = \"opentelemetry-api\" },\n+    { name = \"opentelemetry-exporter-prometheus\" },\n+    { name = \"prometheus-client\" },\n+    { name = \"python-json-logger\" },\n+    { name = \"redis\" },\n+    { name = \"rich\" },\n+    { name = \"typer\" },\n+    { name = \"uuid7\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/6e/a5/925cea9bf8047c4c262f4d789c140f5bfb4a55d2e4dcfeccca1527e77403/pydocket-0.6.3.tar.gz\", hash = \"sha256:a7ffeb2c58fc8a98d5de27cdead5b5ec71f0eaae76ac4f9f0a32b7dc410057a6\", size = 86026 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/ac/8f/710e6733a51ac4a8cb3480405275fd63b2c8cf061109e8ba0d525f0ba108/pydocket-0.6.3-py3-none-any.whl\", hash = \"sha256:2d7a148bc6341e463348ee9e375b1f25f8835289218c46707744dd69a5443c63\", size = 32367 },\n+]\n+\n+[[package]]\n+name = \"pygments\"\n+version = \"2.19.1\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/7c/2d/c3338d48ea6cc0feb8446d8e6937e1408088a72a39937982cc6111d17f84/pygments-2.19.1.tar.gz\", hash = \"sha256:61c16d2a8576dc0649d9f39e089b5f02bcd27fba10d8fb4dcc28173f7a45151f\", size = 4968581 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/8a/0b/9fcc47d19c48b59121088dd6da2488a49d5f72dacf8262e2790a1d2c7d15/pygments-2.19.1-py3-none-any.whl\", hash = \"sha256:9ea1544ad55cecf4b8242fab6dd35a93bbce657034b0611ee383099054ab6d8c\", size = 1225293 },\n+]\n+\n [[package]]\n name = \"pynndescent\"\n version = \"0.5.13\"\n@@ -1134,6 +1280,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl\", hash = \"sha256:d7c01d9e2293916c18baf562d95698754b0dbbb5e74d457c45d4f6561fb9d55d\", size = 20256 },\n ]\n \n+[[package]]\n+name = \"python-json-logger\"\n+version = \"3.3.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/9e/de/d3144a0bceede957f961e975f3752760fbe390d57fbe194baf709d8f1f7b/python_json_logger-3.3.0.tar.gz\", hash = \"sha256:12b7e74b17775e7d565129296105bbe3910842d9d0eb083fc83a6a617aa8df84\", size = 16642 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/08/20/0f2523b9e50a8052bc6a8b732dfc8568abbdc42010aef03a2d750bdab3b2/python_json_logger-3.3.0-py3-none-any.whl\", hash = \"sha256:dd980fae8cffb24c13caf6e158d3d61c0d6d22342f932cb6e9deedab3d35eec7\", size = 15163 },\n+]\n+\n [[package]]\n name = \"python-ulid\"\n version = \"3.0.0\"\n@@ -1274,6 +1429,19 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl\", hash = \"sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6\", size = 64928 },\n ]\n \n+[[package]]\n+name = \"rich\"\n+version = \"14.0.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"markdown-it-py\" },\n+    { name = \"pygments\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/a1/53/830aa4c3066a8ab0ae9a9955976fb770fe9c6102117c8ec4ab3ea62d89e8/rich-14.0.0.tar.gz\", hash = \"sha256:82f1bc23a6a21ebca4ae0c45af9bdbc492ed20231dcb63f297d6d1021a9d5725\", size = 224078 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl\", hash = \"sha256:1c9491e1951aac09caffd42f448ee3d04e58923ffe14993f6e83068dc395d7e0\", size = 243229 },\n+]\n+\n [[package]]\n name = \"ruff\"\n version = \"0.11.4\"\n@@ -1415,6 +1583,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/54/21/f43f0a1fa8b06b32812e0975981f4677d28e0f3271601dc88ac5a5b83220/setuptools-78.1.0-py3-none-any.whl\", hash = \"sha256:3e386e96793c8702ae83d17b853fb93d3e09ef82ec62722e61da5cd22376dcd8\", size = 1256108 },\n ]\n \n+[[package]]\n+name = \"shellingham\"\n+version = \"1.5.4\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/58/15/8b3609fd3830ef7b27b655beb4b4e9c62313a4e8da8c676e142cc210d58e/shellingham-1.5.4.tar.gz\", hash = \"sha256:8dbca0739d487e5bd35ab3ca4b36e11c4078f3a234bfce294b0a0291363404de\", size = 10310 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl\", hash = \"sha256:7ecfff8f2fd72616f7481040475a65b2bf8af90a56c89140852d1120324e8686\", size = 9755 },\n+]\n+\n [[package]]\n name = \"six\"\n version = \"1.17.0\"\n@@ -1651,6 +1828,21 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/c7/30/37a3384d1e2e9320331baca41e835e90a3767303642c7a80d4510152cbcf/triton-3.2.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e5dfa23ba84541d7c0a531dfce76d8bcd19159d50a4a8b14ad01e91734a5c1b0\", size = 253154278 },\n ]\n \n+[[package]]\n+name = \"typer\"\n+version = \"0.15.2\"\n+source = { registry = \"https://pypi.org/simple\" }\n+dependencies = [\n+    { name = \"click\" },\n+    { name = \"rich\" },\n+    { name = \"shellingham\" },\n+    { name = \"typing-extensions\" },\n+]\n+sdist = { url = \"https://files.pythonhosted.org/packages/8b/6f/3991f0f1c7fcb2df31aef28e0594d8d54b05393a0e4e34c65e475c2a5d41/typer-0.15.2.tar.gz\", hash = \"sha256:ab2fab47533a813c49fe1f16b1a370fd5819099c00b119e0633df65f22144ba5\", size = 100711 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/7f/fc/5b29fea8cee020515ca82cc68e3b8e1e34bb19a3535ad854cac9257b414c/typer-0.15.2-py3-none-any.whl\", hash = \"sha256:46a499c6107d645a9c13f7ee46c5d5096cae6f5fc57dd11eccbbb9ae3e44ddfc\", size = 45061 },\n+]\n+\n [[package]]\n name = \"typing-extensions\"\n version = \"4.13.1\"\n@@ -1707,6 +1899,15 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl\", hash = \"sha256:1cee9ad369867bfdbbb48b7dd50374c0967a0bb7710050facf0dd6911440e3df\", size = 128369 },\n ]\n \n+[[package]]\n+name = \"uuid7\"\n+version = \"0.1.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/5c/19/7472bd526591e2192926247109dbf78692e709d3e56775792fec877a7720/uuid7-0.1.0.tar.gz\", hash = \"sha256:8c57aa32ee7456d3cc68c95c4530bc571646defac01895cfc73545449894a63c\", size = 14052 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/b5/77/8852f89a91453956582a85024d80ad96f30a41fed4c2b3dce0c9f12ecc7e/uuid7-0.1.0-py2.py3-none-any.whl\", hash = \"sha256:5e259bb63c8cb4aded5927ff41b444a80d0c7124e8a0ced7cf44efa1f5cccf61\", size = 7477 },\n+]\n+\n [[package]]\n name = \"uvicorn\"\n version = \"0.34.0\"\n@@ -1775,3 +1976,12 @@ wheels = [\n     { url = \"https://files.pythonhosted.org/packages/09/5e/1655cf481e079c1f22d0cabdd4e51733679932718dc23bf2db175f329b76/wrapt-1.17.2-cp313-cp313t-win_amd64.whl\", hash = \"sha256:eaf675418ed6b3b31c7a989fd007fa7c3be66ce14e5c3b27336383604c9da85c\", size = 40750 },\n     { url = \"https://files.pythonhosted.org/packages/2d/82/f56956041adef78f849db6b289b282e72b55ab8045a75abad81898c28d19/wrapt-1.17.2-py3-none-any.whl\", hash = \"sha256:b18f2d1533a71f069c7f82d524a52599053d4c7166e9dd374ae2136b7f40f7c8\", size = 23594 },\n ]\n+\n+[[package]]\n+name = \"zipp\"\n+version = \"3.21.0\"\n+source = { registry = \"https://pypi.org/simple\" }\n+sdist = { url = \"https://files.pythonhosted.org/packages/3f/50/bad581df71744867e9468ebd0bcd6505de3b275e06f202c2cb016e3ff56f/zipp-3.21.0.tar.gz\", hash = \"sha256:2c9958f6430a2040341a52eb608ed6dd93ef4392e02ffe219417c1b28b5dd1f4\", size = 24545 }\n+wheels = [\n+    { url = \"https://files.pythonhosted.org/packages/b7/1a/7e4798e9339adc931158c9d69ecc34f5e6791489d469f5e50ec15e35f458/zipp-3.21.0-py3-none-any.whl\", hash = \"sha256:ac1bbe05fd2991f160ebce24ffbac5f6d11d83dc90891255885223d42b3cd931\", size = 9630 },\n+]"
    }
  ],
  "fix_category": "Change assertion",
  "root_cause_category": "Randomness",
  "root_cause_subcategory": NaN
}