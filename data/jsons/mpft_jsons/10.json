{
  "id": 10,
  "repo": "spark",
  "issue_url": "https://github.com/apache/spark/commit/2606f388a282e548c602cc6575b1ab1f1f10561f",
  "pr_url": "https://github.com/apache/spark/commit/2606f388a282e548c602cc6575b1ab1f1f10561f",
  "issue_description": "This PR allows SparkQA (i.e. Jenkins) to report in its posts to GitHub what category of test failed, if one can be determined.\n\nThe failure categories are:\n- general failure\n- RAT checks failed\n- Scala style checks failed\n- Python style checks failed\n- Build failed\n- Spark unit tests failed\n- PySpark unit tests failed\n- MiMa checks failed\n\nThis PR also fixes the diffing logic used to determine if a patch introduces new classes.\n",
  "files_changed": [
    {
      "filename": "dev/run-tests",
      "status": "modified",
      "patch": "@@ -24,6 +24,16 @@ cd \"$FWDIR\"\n # Remove work directory\n rm -rf ./work\n \n+source \"$FWDIR/dev/run-tests-codes.sh\"\n+\n+CURRENT_BLOCK=$BLOCK_GENERAL\n+\n+function handle_error () {\n+  echo \"[error] Got a return code of $? on line $1 of the run-tests script.\"\n+  exit $CURRENT_BLOCK\n+}\n+\n+\n # Build against the right verison of Hadoop.\n {\n   if [ -n \"$AMPLAB_JENKINS_BUILD_PROFILE\" ]; then\n@@ -91,33 +101,43 @@ if [ -n \"$AMPLAB_JENKINS\" ]; then\n   fi\n fi\n \n-# Fail fast\n-set -e\n set -o pipefail\n+trap 'handle_error $LINENO' ERR\n \n echo \"\"\n echo \"=========================================================================\"\n echo \"Running Apache RAT checks\"\n echo \"=========================================================================\"\n+\n+CURRENT_BLOCK=$BLOCK_RAT\n+\n ./dev/check-license\n \n echo \"\"\n echo \"=========================================================================\"\n echo \"Running Scala style checks\"\n echo \"=========================================================================\"\n+\n+CURRENT_BLOCK=$BLOCK_SCALA_STYLE\n+\n ./dev/lint-scala\n \n echo \"\"\n echo \"=========================================================================\"\n echo \"Running Python style checks\"\n echo \"=========================================================================\"\n+\n+CURRENT_BLOCK=$BLOCK_PYTHON_STYLE\n+\n ./dev/lint-python\n \n echo \"\"\n echo \"=========================================================================\"\n echo \"Building Spark\"\n echo \"=========================================================================\"\n \n+CURRENT_BLOCK=$BLOCK_BUILD\n+\n {\n   # We always build with Hive because the PySpark Spark SQL tests need it.\n   BUILD_MVN_PROFILE_ARGS=\"$SBT_MAVEN_PROFILES_ARGS -Phive\"\n@@ -141,6 +161,8 @@ echo \"=========================================================================\"\n echo \"Running Spark unit tests\"\n echo \"=========================================================================\"\n \n+CURRENT_BLOCK=$BLOCK_SPARK_UNIT_TESTS\n+\n {\n   # If the Spark SQL tests are enabled, run the tests with the Hive profiles enabled.\n   # This must be a single argument, as it is.\n@@ -175,10 +197,16 @@ echo \"\"\n echo \"=========================================================================\"\n echo \"Running PySpark tests\"\n echo \"=========================================================================\"\n+\n+CURRENT_BLOCK=$BLOCK_PYSPARK_UNIT_TESTS\n+\n ./python/run-tests\n \n echo \"\"\n echo \"=========================================================================\"\n echo \"Detecting binary incompatibilites with MiMa\"\n echo \"=========================================================================\"\n+\n+CURRENT_BLOCK=$BLOCK_MIMA\n+\n ./dev/mima"
    },
    {
      "filename": "dev/run-tests-codes.sh",
      "status": "added",
      "patch": "@@ -0,0 +1,27 @@\n+#!/usr/bin/env bash\n+\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+readonly BLOCK_GENERAL=10\n+readonly BLOCK_RAT=11\n+readonly BLOCK_SCALA_STYLE=12\n+readonly BLOCK_PYTHON_STYLE=13\n+readonly BLOCK_BUILD=14\n+readonly BLOCK_SPARK_UNIT_TESTS=15\n+readonly BLOCK_PYSPARK_UNIT_TESTS=16\n+readonly BLOCK_MIMA=17"
    },
    {
      "filename": "dev/run-tests-jenkins",
      "status": "modified",
      "patch": "@@ -26,9 +26,23 @@\n FWDIR=\"$(cd `dirname $0`/..; pwd)\"\n cd \"$FWDIR\"\n \n+source \"$FWDIR/dev/run-tests-codes.sh\"\n+\n COMMENTS_URL=\"https://api.github.com/repos/apache/spark/issues/$ghprbPullId/comments\"\n PULL_REQUEST_URL=\"https://github.com/apache/spark/pull/$ghprbPullId\"\n \n+# Important Environment Variables\n+# ---\n+# $ghprbActualCommit\n+#+  This is the hash of the most recent commit in the PR.\n+#+  The merge-base of this and master is the commit from which the PR was branched.\n+# $sha1\n+#+  If the patch merges cleanly, this is a reference to the merge commit hash\n+#+    (e.g. \"origin/pr/2606/merge\").\n+#+  If the patch does not merge cleanly, it is equal to $ghprbActualCommit.\n+#+  The merge-base of this and master in the case of a clean merge is the most recent commit\n+#+    against master.\n+\n COMMIT_URL=\"https://github.com/apache/spark/commit/${ghprbActualCommit}\"\n # GitHub doesn't auto-link short hashes when submitted via the API, unfortunately. :(\n SHORT_COMMIT_HASH=\"${ghprbActualCommit:0:7}\"\n@@ -84,42 +98,46 @@ function post_message () {\n   fi\n }\n \n+\n+# We diff master...$ghprbActualCommit because that gets us changes introduced in the PR\n+#+ and not anything else added to master since the PR was branched.\n+\n # check PR merge-ability and check for new public classes\n {\n   if [ \"$sha1\" == \"$ghprbActualCommit\" ]; then\n-    merge_note=\" * This patch **does not** merge cleanly!\"\n+    merge_note=\" * This patch **does not merge cleanly**.\"\n   else\n     merge_note=\" * This patch merges cleanly.\"\n+  fi\n+  \n+  source_files=$(\n+      git diff master...$ghprbActualCommit --name-only  `# diff patch against master from branch point` \\\n+    | grep -v -e \"\\/test\"                               `# ignore files in test directories` \\\n+    | grep -e \"\\.py$\" -e \"\\.java$\" -e \"\\.scala$\"        `# include only code files` \\\n+    | tr \"\\n\" \" \"\n+  )\n+  new_public_classes=$(\n+      git diff master...$ghprbActualCommit ${source_files}      `# diff patch against master from branch point` \\\n+    | grep \"^\\+\"                              `# filter in only added lines` \\\n+    | sed -r -e \"s/^\\+//g\"                    `# remove the leading +` \\\n+    | grep -e \"trait \" -e \"class \"            `# filter in lines with these key words` \\\n+    | grep -e \"{\" -e \"(\"                      `# filter in lines with these key words, too` \\\n+    | grep -v -e \"\\@\\@\" -e \"private\"          `# exclude lines with these words` \\\n+    | grep -v -e \"^// \" -e \"^/\\*\" -e \"^ \\* \"  `# exclude comment lines` \\\n+    | sed -r -e \"s/\\{.*//g\"                   `# remove from the { onwards` \\\n+    | sed -r -e \"s/\\}//g\"                     `# just in case, remove }; they mess the JSON` \\\n+    | sed -r -e \"s/\\\"/\\\\\\\\\\\"/g\"               `# escape double quotes; they mess the JSON` \\\n+    | sed -r -e \"s/^(.*)$/\\`\\1\\`/g\"           `# surround with backticks for style` \\\n+    | sed -r -e \"s/^/  \\* /g\"                 `# prepend '  *' to start of line` \\\n+    | sed -r -e \"s/$/\\\\\\n/g\"                  `# append newline to end of line` \\\n+    | tr -d \"\\n\"                              `# remove actual LF characters`\n+  )\n \n-    source_files=$(\n-        git diff master... --name-only              `# diff patch against master from branch point` \\\n-      | grep -v -e \"\\/test\"                         `# ignore files in test directories` \\\n-      | grep -e \"\\.py$\" -e \"\\.java$\" -e \"\\.scala$\"  `# include only code files` \\\n-      | tr \"\\n\" \" \"\n-    )\n-    new_public_classes=$(\n-        git diff master... ${source_files}      `# diff patch against master from branch point` \\\n-      | grep \"^\\+\"                              `# filter in only added lines` \\\n-      | sed -r -e \"s/^\\+//g\"                    `# remove the leading +` \\\n-      | grep -e \"trait \" -e \"class \"            `# filter in lines with these key words` \\\n-      | grep -e \"{\" -e \"(\"                      `# filter in lines with these key words, too` \\\n-      | grep -v -e \"\\@\\@\" -e \"private\"          `# exclude lines with these words` \\\n-      | grep -v -e \"^// \" -e \"^/\\*\" -e \"^ \\* \"  `# exclude comment lines` \\\n-      | sed -r -e \"s/\\{.*//g\"                   `# remove from the { onwards` \\\n-      | sed -r -e \"s/\\}//g\"                     `# just in case, remove }; they mess the JSON` \\\n-      | sed -r -e \"s/\\\"/\\\\\\\\\\\"/g\"               `# escape double quotes; they mess the JSON` \\\n-      | sed -r -e \"s/^(.*)$/\\`\\1\\`/g\"           `# surround with backticks for style` \\\n-      | sed -r -e \"s/^/  \\* /g\"                 `# prepend '  *' to start of line` \\\n-      | sed -r -e \"s/$/\\\\\\n/g\"                  `# append newline to end of line` \\\n-      | tr -d \"\\n\"                              `# remove actual LF characters`\n-    )\n-\n-    if [ \"$new_public_classes\" == \"\" ]; then\n-      public_classes_note=\" * This patch adds no public classes.\"\n-    else\n-      public_classes_note=\" * This patch adds the following public classes _(experimental)_:\"\n-      public_classes_note=\"${public_classes_note}\\n${new_public_classes}\"\n-    fi\n+  if [ -z \"$new_public_classes\" ]; then\n+    public_classes_note=\" * This patch adds no public classes.\"\n+  else\n+    public_classes_note=\" * This patch adds the following public classes _(experimental)_:\"\n+    public_classes_note=\"${public_classes_note}\\n${new_public_classes}\"\n   fi\n }\n \n@@ -147,12 +165,30 @@ function post_message () {\n \n     post_message \"$fail_message\"\n     exit $test_result\n+  elif [ \"$test_result\" -eq \"0\" ]; then\n+    test_result_note=\" * This patch **passes all tests**.\"\n   else\n-    if [ \"$test_result\" -eq \"0\" ]; then\n-      test_result_note=\" * This patch **passes** unit tests.\"\n+    if [ \"$test_result\" -eq \"$BLOCK_GENERAL\" ]; then\n+      failing_test=\"some tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_RAT\" ]; then\n+      failing_test=\"RAT tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_SCALA_STYLE\" ]; then\n+      failing_test=\"Scala style tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_PYTHON_STYLE\" ]; then\n+      failing_test=\"Python style tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_BUILD\" ]; then\n+      failing_test=\"to build\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_SPARK_UNIT_TESTS\" ]; then\n+      failing_test=\"Spark unit tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_PYSPARK_UNIT_TESTS\" ]; then\n+      failing_test=\"PySpark unit tests\"\n+    elif [ \"$test_result\" -eq \"$BLOCK_MIMA\" ]; then\n+      failing_test=\"MiMa tests\"\n     else\n-      test_result_note=\" * This patch **fails** unit tests.\"\n+      failing_test=\"some tests\"\n     fi\n+    \n+    test_result_note=\" * This patch **fails $failing_test**.\"\n   fi\n }\n "
    }
  ],
  "fix_category": "Sleep",
  "root_cause_category": "Time",
  "root_cause_subcategory": NaN
}