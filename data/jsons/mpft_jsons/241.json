{
  "id": 241,
  "repo": "rocksdb",
  "issue_url": "https://github.com/facebook/rocksdb/pull/13234",
  "pr_url": "https://github.com/facebook/rocksdb/pull/13234",
  "issue_description": "Summary: `DBErrorHandlingFSTest.AtomicFlushNoSpaceError` is flaky due to seg fault during error recovery:\r\n```\r\n...\r\nframe #5: 0x00007f0b3ea0a9d6 librocksdb.so.9.10`rocksdb::VersionSet::GetObsoleteFiles(std::vector<rocksdb::ObsoleteFileInfo, std::allocator<rocksdb::ObsoleteFileInfo>>*, std::vector<rocksdb::ObsoleteBlobFileInfo, std::allocator<rocksdb::ObsoleteBlobFileInfo>>*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>>>*, unsigned long) [inlined] std::vector<rocksdb::ObsoleteFileInfo, std::allocator<rocksdb::ObsoleteFileInfo>>::begin(this=<unavailable>) at stl_vector.h:812:16\r\nframe #6: 0x00007f0b3ea0a9d6 librocksdb.so.9.10`rocksdb::VersionSet::GetObsoleteFiles(this=0x0000000000000000, files=size=0, blob_files=size=0, manifest_filenames=size=0, min_pending_output=18446744073709551615) at version_set.cc:7258:18\r\nframe #7: 0x00007f0b3e8ccbc0 librocksdb.so.9.10`rocksdb::DBImpl::FindObsoleteFiles(this=<unavailable>, job_context=<unavailable>, force=<unavailable>, no_full_scan=<unavailable>) at db_impl_files.cc:162:30\r\nframe #8: 0x00007f0b3e85e698 librocksdb.so.9.10`rocksdb::DBImpl::ResumeImpl(this=<unavailable>, context=<unavailable>) at db_impl.cc:434:20\r\nframe #9: 0x00007f0b3e921516 librocksdb.so.9.10`rocksdb::ErrorHandler::RecoverFromBGError(this=<unavailable>, is_manual=<unavailable>) at error_handler.cc:632:46\r\n```\r\n\r\nI suspect that this is due to DB being destructed and reopened during recovery. Specifically, the [ClearBGError() call](https://github.com/facebook/rocksdb/blob/c72e79a262bf696faf5f8becabf92374fc14b464/db/db_impl/db_impl.cc#L425) can release and re-acquire mutex, and DB can be closed during this time. So it's not safe to access DB states after ClearBGError(). There was a similar story in #9496. [Moving the obsolete files logic after ClearBGError()](https://github.com/facebook/rocksdb/pull/11955) probably makes the seg fault more easily triggered.\r\n\r\nThis PR updates `ClearBGError()` to guarantee that db close cannot finish until the method returns and the mutex is released. So that we can safely access DB states after calling it.\r\n\r\n\r\nTest plan: I could not trigger the seg fault locally, will just monitor future test failures.\r\n\r\n",
  "files_changed": [
    {
      "filename": "db/db_impl/db_impl.cc",
      "status": "modified",
      "patch": "@@ -418,26 +418,26 @@ Status DBImpl::ResumeImpl(DBRecoverContext context) {\n     }\n   }\n \n-  if (s.ok()) {\n-    // This will notify and unblock threads waiting for error recovery to\n-    // finish. Those previouly waiting threads can now proceed, which may\n-    // include closing the db.\n-    s = error_handler_.ClearBGError();\n-  } else {\n-    // NOTE: this is needed to pass ASSERT_STATUS_CHECKED\n-    // in the DBSSTTest.DBWithMaxSpaceAllowedRandomized test.\n-    // See https://github.com/facebook/rocksdb/pull/7715#issuecomment-754947952\n-    error_handler_.GetRecoveryError().PermitUncheckedError();\n-  }\n-\n   JobContext job_context(0);\n   FindObsoleteFiles(&job_context, true);\n   mutex_.Unlock();\n+  // If DB shutdown initiated here, it will wait for this ongoing recovery.\n   job_context.manifest_file_number = 1;\n   if (job_context.HaveSomethingToDelete()) {\n     PurgeObsoleteFiles(job_context);\n   }\n   job_context.Clean();\n+  mutex_.Lock();\n+\n+  if (s.ok()) {\n+    // Will notify and unblock threads waiting for error recovery to finish.\n+    s = error_handler_.ClearBGError();\n+  } else {\n+    // NOTE: this is needed to pass ASSERT_STATUS_CHECKED\n+    // in the DBSSTTest.DBWithMaxSpaceAllowedRandomized test.\n+    // See https://github.com/facebook/rocksdb/pull/7715#issuecomment-754947952\n+    error_handler_.GetRecoveryError().PermitUncheckedError();\n+  }\n \n   if (s.ok()) {\n     ROCKS_LOG_INFO(immutable_db_options_.info_log, \"Successfully resumed DB\");\n@@ -446,7 +446,6 @@ Status DBImpl::ResumeImpl(DBRecoverContext context) {\n                    s.ToString().c_str());\n   }\n \n-  mutex_.Lock();\n   // Check for shutdown again before scheduling further compactions,\n   // since we released and re-acquired the lock above\n   if (shutdown_initiated_) {\n@@ -540,8 +539,8 @@ Status DBImpl::CloseHelper() {\n   // continuing with the shutdown\n   mutex_.Lock();\n   shutdown_initiated_ = true;\n-  error_handler_.CancelErrorRecovery();\n-  while (error_handler_.IsRecoveryInProgress()) {\n+  error_handler_.CancelErrorRecoveryForShutDown();\n+  while (!error_handler_.ReadyForShutdown()) {\n     bg_cv_.Wait();\n   }\n   mutex_.Unlock();"
    },
    {
      "filename": "db/db_impl/db_impl_files.cc",
      "status": "modified",
      "patch": "@@ -159,6 +159,7 @@ void DBImpl::FindObsoleteFiles(JobContext* job_context, bool force,\n \n   // Get obsolete files.  This function will also update the list of\n   // pending files in VersionSet().\n+  assert(versions_);\n   versions_->GetObsoleteFiles(\n       &job_context->sst_delete_files, &job_context->blob_delete_files,\n       &job_context->manifest_delete_files, job_context->min_pending_output);"
    },
    {
      "filename": "db/error_handler.cc",
      "status": "modified",
      "patch": "@@ -227,7 +227,7 @@ std::map<std::tuple<BackgroundErrorReason, bool>, Status::Severity>\n          Status::Severity::kFatalError},\n };\n \n-void ErrorHandler::CancelErrorRecovery() {\n+void ErrorHandler::CancelErrorRecoveryForShutDown() {\n   db_mutex_->AssertHeld();\n \n   // We'll release the lock before calling sfm, so make sure no new\n@@ -585,8 +585,15 @@ Status ErrorHandler::ClearBGError() {\n     recovery_error_.PermitUncheckedError();\n     recovery_in_prog_ = false;\n     soft_error_no_bg_work_ = false;\n-    EventHelpers::NotifyOnErrorRecoveryEnd(db_options_.listeners, old_bg_error,\n-                                           bg_error_, db_mutex_);\n+    if (!db_->shutdown_initiated_) {\n+      // NotifyOnErrorRecoveryEnd() may release and re-acquire db_mutex_.\n+      // Prevent DB from being closed while we notify listeners. DB close will\n+      // wait until allow_db_shutdown_ = true, see ReadyForShutdown().\n+      allow_db_shutdown_ = false;\n+      EventHelpers::NotifyOnErrorRecoveryEnd(\n+          db_options_.listeners, old_bg_error, bg_error_, db_mutex_);\n+      allow_db_shutdown_ = true;\n+    }\n   }\n   return recovery_error_;\n }"
    },
    {
      "filename": "db/error_handler.h",
      "status": "modified",
      "patch": "@@ -44,6 +44,7 @@ class ErrorHandler {\n         auto_recovery_(false),\n         recovery_in_prog_(false),\n         soft_error_no_bg_work_(false),\n+        allow_db_shutdown_(true),\n         is_db_stopped_(false),\n         bg_error_stats_(db_options.statistics) {\n     // Clear the checked flag for uninitialized errors\n@@ -63,6 +64,12 @@ class ErrorHandler {\n \n   Status GetRecoveryError() const { return recovery_error_; }\n \n+  // REQUIREs: db mutex held\n+  //\n+  // Returns non-OK status if encountered error during recovery.\n+  // Returns OK if bg error is successfully cleared. May releases and\n+  // re-acquire db mutex to notify listeners. However, DB close (if initiated)\n+  // will be blocked until db mutex is released after return.\n   Status ClearBGError();\n \n   bool IsDBStopped() { return is_db_stopped_.load(std::memory_order_acquire); }\n@@ -79,8 +86,14 @@ class ErrorHandler {\n \n   bool IsRecoveryInProgress() { return recovery_in_prog_; }\n \n+  // REQUIRES: db mutex held\n+  bool ReadyForShutdown() {\n+    db_mutex_->AssertHeld();\n+    return !recovery_in_prog_ && allow_db_shutdown_;\n+  }\n+\n   Status RecoverFromBGError(bool is_manual = false);\n-  void CancelErrorRecovery();\n+  void CancelErrorRecoveryForShutDown();\n \n   void EndAutoRecovery();\n \n@@ -121,6 +134,8 @@ class ErrorHandler {\n   // A flag to indicate that for the soft error, we should not allow any\n   // background work except the work is from recovery.\n   bool soft_error_no_bg_work_;\n+  // Used in ClearBGError() to prevent DB from being closed.\n+  bool allow_db_shutdown_;\n \n   // Used to store the context for recover, such as flush reason.\n   DBRecoverContext recover_context_;"
    }
  ],
  "fix_category": "Other",
  "root_cause_category": "Concurrency",
  "root_cause_subcategory": NaN
}