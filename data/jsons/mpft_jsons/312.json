{
  "id": 312,
  "repo": "spark",
  "issue_url": "https://github.com/apache/spark/pull/52264",
  "pr_url": "https://github.com/apache/spark/pull/52264",
  "issue_description": "### What changes were proposed in this pull request?\r\nThis PR aims to fix flaky tests in `SparkConnectServiceSuite` which are caused by `executorHolder` [undefined](https://github.com/apache/spark/blob/ab9a63626018156b3e0f267f14409c30031692b7/sql/connect/server/src/test/scala/org/apache/spark/sql/connect/planner/SparkConnectServiceSuite.scala#L908).\r\nThe conditions to reproduce this issue are:\r\n\r\n(1) The operation finishes before its `executeHolder` is set in [MockSparkListener#onOtherEvent](https://github.com/apache/spark/blob/ab9a63626018156b3e0f267f14409c30031692b7/sql/connect/server/src/test/scala/org/apache/spark/sql/connect/planner/SparkConnectServiceSuite.scala#L961).\r\n(2) `executeHolder` is accessed through calling `verifyEvents.onComplete` after the operation finishes. \r\n\r\n`SparkListenerConnectOperationStarted` is posted asynchronously with the corresponding operation so the condition (1) can be met. After an operation finishes, `executeHolder` is [removed from a map](https://github.com/apache/spark/blob/af16aa8e11c223642f928b0b9893854a851d70bb/sql/connect/server/src/main/scala/org/apache/spark/sql/connect/service/SparkConnectExecutionManager.scala#L153) so if the condition (1) is met, `executeHolder` is never set because `SparkConnectService.executionManager.getExecuteHolder` consistently returns `None`.\r\n\r\nOne example of the test affected by this issue is `SPARK-43923: commands send events - get_resources_command`.\r\nYou can easily reproduce this issue by inserting sleep into `MockSparkListener#onOtherEvent` like as follows.\r\n\r\n```\r\n   val executeKey =\r\n     ExecuteKey(sessionHolder.userId, sessionHolder.sessionId, e.operationId)\r\n+  Thread.sleep(1000)\r\n   executeHolder = SparkConnectService.executionManager.getExecuteHolder(executeKey)\r\n```\r\n\r\nAnd then, run test.\r\n```\r\n$ build/sbt 'connect/testOnly org.apache.spark.sql.connect.planner.SparkConnectServiceSuite -- -z \"get_resources_command\"'\r\n```\r\nTo resolve this issue, this PR proposes:\r\n\r\n* Change `VerifyEvents#onCompleted` just to assert `executeHolder.eventsManager.getProducedRowCount == producedRowCount`\r\n* Call `VerifyEvents#onCompleted` from `StreamObserver#onCompleted`\r\n* Add `VerifyEvents#assertClosed` to check if the status is `Closed`\r\n\r\n### Why are the changes needed?\r\nFor test stability.\r\n\r\n### Does this PR introduce _any_ user-facing change?\r\nNo.\r\n\r\n### How was this patch tested?\r\nInserting `Thread.sleep(1000)` like mentioned above and then run `SparkConnectServiceSuite`.\r\n\r\n### Was this patch authored or co-authored using generative AI tooling?\r\nNo.",
  "files_changed": [
    {
      "filename": "sql/connect/server/src/test/scala/org/apache/spark/sql/connect/planner/SparkConnectServiceSuite.scala",
      "status": "modified",
      "patch": "@@ -192,10 +192,11 @@ class SparkConnectServiceSuite\n           }\n \n           override def onCompleted(): Unit = {\n+            verifyEvents.onCompleted(Some(100))\n             done = true\n           }\n         })\n-      verifyEvents.onCompleted(Some(100))\n+      verifyEvents.assertClosed()\n       // The current implementation is expected to be blocking. This is here to make sure it is.\n       assert(done)\n \n@@ -293,10 +294,11 @@ class SparkConnectServiceSuite\n           }\n \n           override def onCompleted(): Unit = {\n+            verifyEvents.onCompleted(Some(6))\n             done = true\n           }\n         })\n-      verifyEvents.onCompleted(Some(6))\n+      verifyEvents.assertClosed()\n       // The current implementation is expected to be blocking. This is here to make sure it is.\n       assert(done)\n \n@@ -529,10 +531,11 @@ class SparkConnectServiceSuite\n           }\n \n           override def onCompleted(): Unit = {\n+            verifyEvents.onCompleted(producedNumRows)\n             done = true\n           }\n         })\n-      verifyEvents.onCompleted(producedNumRows)\n+      verifyEvents.assertClosed()\n       // The current implementation is expected to be blocking.\n       // This is here to make sure it is.\n       assert(done)\n@@ -620,7 +623,7 @@ class SparkConnectServiceSuite\n           }\n         })\n       thread.join()\n-      verifyEvents.onCompleted()\n+      verifyEvents.assertClosed()\n     }\n   }\n \n@@ -683,7 +686,7 @@ class SparkConnectServiceSuite\n           }\n         })\n       assert(failures.isEmpty, s\"this should have no failures but got $failures\")\n-      verifyEvents.onCompleted()\n+      verifyEvents.assertClosed()\n     }\n   }\n \n@@ -925,6 +928,8 @@ class SparkConnectServiceSuite\n     }\n     def onCompleted(producedRowCount: Option[Long] = None): Unit = {\n       assert(executeHolder.eventsManager.getProducedRowCount == producedRowCount)\n+    }\n+    def assertClosed(): Unit = {\n       // The eventsManager is closed asynchronously\n       Eventually.eventually(EVENT_WAIT_TIMEOUT) {\n         assert("
    }
  ],
  "fix_category": "WaitFor",
  "root_cause_category": "Concurrency",
  "root_cause_subcategory": NaN
}