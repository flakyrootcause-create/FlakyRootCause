{
  "id": 247,
  "repo": "hadoop",
  "issue_url": "https://github.com/apache/hadoop/pull/3720",
  "pr_url": "https://github.com/apache/hadoop/pull/3720",
  "issue_description": "### Description of PR\r\ntestDecommissionStatus keeps failing intermittently.\r\n```\r\n[ERROR] testDecommissionStatus(org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor)  Time elapsed: 3.299 s  <<< FAILURE!\r\njava.lang.AssertionError: Unexpected num under-replicated blocks expected:<4> but was:<3>\r\n\tat org.junit.Assert.fail(Assert.java:89)\r\n\tat org.junit.Assert.failNotEquals(Assert.java:835)\r\n\tat org.junit.Assert.assertEquals(Assert.java:647)\r\n\tat org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.checkDecommissionStatus(TestDecommissioningStatus.java:169)\r\n\tat org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.testDecommissionStatus(TestDecommissioningStatusWithBackoffMonitor.java:136)\r\n```\r\n\r\n### How was this patch tested?\r\nLocal run of unit test\r\n\r\n### For code changes:\r\n\r\n- [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?\r\n",
  "files_changed": [
    {
      "filename": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java",
      "status": "modified",
      "patch": "@@ -398,6 +398,28 @@ public static void assertExceptionContains(String expectedText,\n   public static void waitFor(final Supplier<Boolean> check,\n       final long checkEveryMillis, final long waitForMillis)\n       throws TimeoutException, InterruptedException {\n+    waitFor(check, checkEveryMillis, waitForMillis, null);\n+  }\n+\n+  /**\n+   * Wait for the specified test to return true. The test will be performed\n+   * initially and then every {@code checkEveryMillis} until at least\n+   * {@code waitForMillis} time has expired. If {@code check} is null or\n+   * {@code waitForMillis} is less than {@code checkEveryMillis} this method\n+   * will throw an {@link IllegalArgumentException}.\n+   *\n+   * @param check the test to perform.\n+   * @param checkEveryMillis how often to perform the test.\n+   * @param waitForMillis the amount of time after which no more tests will be\n+   * performed.\n+   * @param errorMsg error message to provide in TimeoutException.\n+   * @throws TimeoutException if the test does not return true in the allotted\n+   * time.\n+   * @throws InterruptedException if the method is interrupted while waiting.\n+   */\n+  public static void waitFor(final Supplier<Boolean> check,\n+      final long checkEveryMillis, final long waitForMillis,\n+      final String errorMsg) throws TimeoutException, InterruptedException {\n     Objects.requireNonNull(check, ERROR_MISSING_ARGUMENT);\n     if (waitForMillis < checkEveryMillis) {\n       throw new IllegalArgumentException(ERROR_INVALID_ARGUMENT);\n@@ -412,9 +434,12 @@ public static void waitFor(final Supplier<Boolean> check,\n     }\n \n     if (!result) {\n-      throw new TimeoutException(\"Timed out waiting for condition. \" +\n-          \"Thread diagnostics:\\n\" +\n-          TimedOutTestsListener.buildThreadDiagnosticString());\n+      final String exceptionErrorMsg = \"Timed out waiting for condition. \"\n+          + (org.apache.commons.lang3.StringUtils.isNotEmpty(errorMsg)\n+          ? \"Error Message: \" + errorMsg : \"\")\n+          + \"\\nThread diagnostics:\\n\" +\n+          TimedOutTestsListener.buildThreadDiagnosticString();\n+      throw new TimeoutException(exceptionErrorMsg);\n     }\n   }\n "
    },
    {
      "filename": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDecommissioningStatus.java",
      "status": "modified",
      "patch": "@@ -27,7 +27,10 @@\n import java.util.Arrays;\n import java.util.List;\n \n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n import org.apache.commons.io.output.ByteArrayOutputStream;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.BlockLocation;\n@@ -57,11 +60,12 @@\n import org.apache.hadoop.hdfs.tools.DFSAdmin;\n import org.apache.hadoop.hdfs.util.HostsFileWriter;\n import org.apache.hadoop.test.GenericTestUtils;\n-import org.apache.log4j.Level;\n-import org.apache.log4j.Logger;\n import org.junit.After;\n import org.junit.Before;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.slf4j.event.Level;\n \n /**\n  * This class tests the decommissioning of nodes.\n@@ -75,7 +79,8 @@ public class TestDecommissioningStatus {\n   private static FileSystem fileSys;\n   private static HostsFileWriter hostsFileWriter;\n   private static Configuration conf;\n-  private Logger LOG;\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(TestDecommissioningStatus.class);\n \n   final ArrayList<String> decommissionedNodes = new ArrayList<String>(numDatanodes);\n   \n@@ -102,8 +107,8 @@ public void setUp() throws Exception {\n     fileSys = cluster.getFileSystem();\n     cluster.getNamesystem().getBlockManager().getDatanodeManager()\n         .setHeartbeatExpireInterval(3000);\n-    Logger.getLogger(DatanodeAdminManager.class).setLevel(Level.DEBUG);\n-    LOG = Logger.getLogger(TestDecommissioningStatus.class);\n+    GenericTestUtils.setLogLevel(\n+        LoggerFactory.getLogger(DatanodeAdminManager.class), Level.DEBUG);\n   }\n \n   @After\n@@ -142,17 +147,30 @@ private void decommissionNode(String dnName)\n \n   private void checkDecommissionStatus(DatanodeDescriptor decommNode,\n       int expectedUnderRep, int expectedDecommissionOnly,\n-      int expectedUnderRepInOpenFiles) {\n-    assertEquals(\"Unexpected num under-replicated blocks\",\n-        expectedUnderRep,\n-        decommNode.getLeavingServiceStatus().getUnderReplicatedBlocks());\n-    assertEquals(\"Unexpected number of decom-only replicas\",\n-        expectedDecommissionOnly,\n-        decommNode.getLeavingServiceStatus().getOutOfServiceOnlyReplicas());\n-    assertEquals(\n-        \"Unexpected number of replicas in under-replicated open files\",\n-        expectedUnderRepInOpenFiles,\n-        decommNode.getLeavingServiceStatus().getUnderReplicatedInOpenFiles());\n+      int expectedUnderRepInOpenFiles) throws TimeoutException,\n+      InterruptedException {\n+    String errorMsg;\n+    errorMsg = \"Under replicated blocks. Expected: \"\n+        + expectedUnderRep + \" , Actual: \"\n+        + decommNode.getLeavingServiceStatus().getUnderReplicatedBlocks();\n+    GenericTestUtils.waitFor(\n+        () -> expectedUnderRep == decommNode.getLeavingServiceStatus()\n+            .getUnderReplicatedBlocks(),\n+        1000, TimeUnit.SECONDS.toMillis(10), errorMsg);\n+    errorMsg = \"OutOfService only replicas. Expected: \"\n+        + expectedDecommissionOnly + \" , Actual: \"\n+        + decommNode.getLeavingServiceStatus().getOutOfServiceOnlyReplicas();\n+    GenericTestUtils.waitFor(\n+        () -> expectedDecommissionOnly == decommNode.getLeavingServiceStatus()\n+            .getOutOfServiceOnlyReplicas(),\n+        1000, TimeUnit.SECONDS.toMillis(10), errorMsg);\n+    errorMsg = \"UnderReplicated in open files. Expected: \"\n+        + expectedUnderRepInOpenFiles + \" , Actual: \"\n+        + decommNode.getLeavingServiceStatus().getUnderReplicatedInOpenFiles();\n+    GenericTestUtils.waitFor(\n+        () -> expectedUnderRepInOpenFiles == decommNode\n+            .getLeavingServiceStatus().getUnderReplicatedInOpenFiles(),\n+        1000, TimeUnit.SECONDS.toMillis(10), errorMsg);\n   }\n \n   private void checkDFSAdminDecommissionStatus(\n@@ -247,6 +265,7 @@ public void testDecommissionStatus() throws Exception {\n \n     FSNamesystem fsn = cluster.getNamesystem();\n     final DatanodeManager dm = fsn.getBlockManager().getDatanodeManager();\n+    verifyInitialState(fsn, dm);\n     for (int iteration = 0; iteration < numDatanodes; iteration++) {\n       String downnode = decommissionNode(client, iteration);\n       dm.refreshNodes(conf);\n@@ -255,14 +274,13 @@ public void testDecommissionStatus() throws Exception {\n       // Block until the admin's monitor updates the number of tracked nodes.\n       waitForDecommissionedNodes(dm.getDatanodeAdminManager(), iteration + 1);\n       final List<DatanodeDescriptor> decommissioningNodes = dm.getDecommissioningNodes();\n+      assertEquals(decommissioningNodes.size(), iteration + 1);\n       if (iteration == 0) {\n-        assertEquals(decommissioningNodes.size(), 1);\n         DatanodeDescriptor decommNode = decommissioningNodes.get(0);\n         checkDecommissionStatus(decommNode, 3, 0, 1);\n         checkDFSAdminDecommissionStatus(decommissioningNodes.subList(0, 1),\n             fileSys, admin);\n       } else {\n-        assertEquals(decommissioningNodes.size(), 2);\n         DatanodeDescriptor decommNode1 = decommissioningNodes.get(0);\n         DatanodeDescriptor decommNode2 = decommissioningNodes.get(1);\n         // This one is still 3,3,1 since it passed over the UC block \n@@ -284,6 +302,69 @@ public void testDecommissionStatus() throws Exception {\n     AdminStatesBaseTest.cleanupFile(fileSys, file2);\n   }\n \n+  // Why do we verify initial state of DataNodes here?\n+  // Before we start actual decommission testing, we should ensure that\n+  // total 8 blocks (original 4 blocks of 2 files and 4 replicas) are\n+  // present over two Datanodes available. If we don't wait until all 8 blocks\n+  // are reported live by BlockManager, we might get to a situation\n+  // where one of the replicas might not yet been present on any of Datanodes\n+  // and we start decommissioning process, and then it would result in\n+  // flaky test because total (no of under replicated blocks, no of outOfService\n+  // only replicas, no of under replicated in open files) counts would be\n+  // incorrect.\n+  protected void verifyInitialState(FSNamesystem fsn, DatanodeManager dm)\n+      throws InterruptedException {\n+    dm.getDatanodes().forEach(datanodeDescriptor -> {\n+      try {\n+        checkDecommissionStatus(datanodeDescriptor, 0, 0, 0);\n+      } catch (TimeoutException | InterruptedException e) {\n+        throw new AssertionError(\"Datanode not in good state.\", e);\n+      }\n+    });\n+    int c = 0;\n+    int totalBlocks;\n+    long totalReplicatedBlocks;\n+    while (true) {\n+      totalBlocks = fsn.getBlockManager().getTotalBlocks();\n+      totalReplicatedBlocks = fsn.getBlockManager().getTotalReplicatedBlocks();\n+      if (totalBlocks == 4 && totalReplicatedBlocks == 4) {\n+        break;\n+      } else {\n+        if (c == 4) {\n+          throw new AssertionError(\"Unexpected Total blocks \" + totalBlocks\n+              + \" and replicated blocks \" + totalReplicatedBlocks);\n+        }\n+        Thread.sleep(3000);\n+      }\n+      c++;\n+    }\n+    c = 0;\n+    AtomicInteger total = new AtomicInteger(0);\n+    AtomicInteger sufficientBlocksSuccess = new AtomicInteger(0);\n+    while (true) {\n+      total.set(0);\n+      sufficientBlocksSuccess.set(0);\n+      dm.getDatanodes().forEach(\n+          datanodeDescriptor -> {\n+            total.addAndGet(datanodeDescriptor.numBlocks());\n+            if (datanodeDescriptor.numBlocks() == 4) {\n+              sufficientBlocksSuccess.incrementAndGet();\n+            }\n+          });\n+      if (total.get() == 8 && sufficientBlocksSuccess.get() == 2) {\n+        break;\n+      } else {\n+        if (c == 4) {\n+          throw new AssertionError(\"Unexpected Total blocks \" + total.get()\n+              + \" from Datanode Storage. 4 blocks per Datanode Storage\"\n+              + \" expected from each DataNode\");\n+        }\n+        Thread.sleep(3000);\n+      }\n+      c++;\n+    }\n+  }\n+\n   /**\n    * Verify a DN remains in DECOMMISSION_INPROGRESS state if it is marked\n    * as dead before decommission has completed. That will allow DN to resume\n@@ -367,8 +448,8 @@ public void testDecommissionStatusAfterDNRestart() throws Exception {\n    */\n   @Test(timeout=120000)\n   public void testDecommissionDeadDN() throws Exception {\n-    Logger log = Logger.getLogger(DatanodeAdminManager.class);\n-    log.setLevel(Level.DEBUG);\n+    Logger log = LoggerFactory.getLogger(DatanodeAdminManager.class);\n+    GenericTestUtils.setLogLevel(log, Level.DEBUG);\n     DatanodeID dnID = cluster.getDataNodes().get(0).getDatanodeId();\n     String dnName = dnID.getXferAddr();\n     DataNodeProperties stoppedDN = cluster.stopDataNode(0);"
    }
  ],
  "fix_category": "WaitFor",
  "root_cause_category": "Time",
  "root_cause_subcategory": NaN
}