{
  "id": 239,
  "repo": "duckdb",
  "issue_url": "https://github.com/duckdb/duckdb/pull/14367",
  "pr_url": "https://github.com/duckdb/duckdb/pull/14367",
  "issue_description": "Fixes #14294\r\n\r\nI ran the test with 1 thread and saw it consistently yielded 5 files, so this should be the proper lower bound.",
  "files_changed": [
    {
      "filename": "test/sql/copy/file_size_bytes.test",
      "status": "modified",
      "patch": "@@ -135,7 +135,6 @@ SELECT count(*) > 1 FROM glob('__TEST_DIR__/file_size_bytes_csv5/*.csv')\n true\n \n # each thread sees ~240kb if it's balanced, what about a 190kb limit\n-# even in the case of extreme thread imbalance, this always yield around 8 files\n statement ok\n COPY (FROM bigdata) TO '__TEST_DIR__/file_size_bytes_csv6' (FORMAT CSV, FILE_SIZE_BYTES '190kb', PER_THREAD_OUTPUT TRUE);\n \n@@ -144,9 +143,9 @@ SELECT COUNT(*) FROM read_csv_auto('__TEST_DIR__/file_size_bytes_csv6/*.csv')\n ----\n 100000\n \n-# ~2 files per thread, around 8 in total\n+# ~2 files per thread, around 8 in total (5 output files in case of extreme thread imbalance and only 1 thread runs)\n query I\n-SELECT count(*) BETWEEN 6 AND 10 FROM glob('__TEST_DIR__/file_size_bytes_csv6/*.csv')\n+SELECT count(*) BETWEEN 5 AND 10 FROM glob('__TEST_DIR__/file_size_bytes_csv6/*.csv')\n ----\n 1\n "
    }
  ],
  "fix_category": "Other",
  "root_cause_category": "Concurrency",
  "root_cause_subcategory": NaN
}